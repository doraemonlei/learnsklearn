{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#支持向量机\" data-toc-modified-id=\"支持向量机-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>支持向量机</a></span></li><li><span><a href=\"#分类\" data-toc-modified-id=\"分类-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>分类</a></span><ul class=\"toc-item\"><li><span><a href=\"#多分类\" data-toc-modified-id=\"多分类-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>多分类</a></span></li><li><span><a href=\"#得分和概率\" data-toc-modified-id=\"得分和概率-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>得分和概率</a></span></li><li><span><a href=\"#非均衡问题\" data-toc-modified-id=\"非均衡问题-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>非均衡问题</a></span></li></ul></li><li><span><a href=\"#回归\" data-toc-modified-id=\"回归-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>回归</a></span></li><li><span><a href=\"#密度估计,-异常（novelty）检测\" data-toc-modified-id=\"密度估计,-异常（novelty）检测-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>密度估计, 异常（novelty）检测</a></span></li><li><span><a href=\"#复杂度\" data-toc-modified-id=\"复杂度-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>复杂度</a></span></li><li><span><a href=\"#使用诀窍\" data-toc-modified-id=\"使用诀窍-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>使用诀窍</a></span></li><li><span><a href=\"#核函数\" data-toc-modified-id=\"核函数-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>核函数</a></span><ul class=\"toc-item\"><li><span><a href=\"#自定义核\" data-toc-modified-id=\"自定义核-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>自定义核</a></span><ul class=\"toc-item\"><li><span><a href=\"#使用-python-函数作为内核\" data-toc-modified-id=\"使用-python-函数作为内核-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>使用 python 函数作为内核</a></span></li><li><span><a href=\"#使用-Gram-矩阵\" data-toc-modified-id=\"使用-Gram-矩阵-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>使用 Gram 矩阵</a></span></li><li><span><a href=\"#RBF\" data-toc-modified-id=\"RBF-7.1.3\"><span class=\"toc-item-num\">7.1.3&nbsp;&nbsp;</span>RBF</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm.LinearSVC([penalty, loss, dual, tol, C, …])\tLinear Support Vector Classification.  \n",
    "svm.LinearSVR([epsilon, tol, C, loss, …])\tLinear Support Vector Regression.  \n",
    "svm.NuSVC([nu, kernel, degree, gamma, …])\tNu-Support Vector Classification.  \n",
    "svm.NuSVR([nu, C, kernel, degree, gamma, …])\tNu Support Vector Regression.  \n",
    "svm.OneClassSVM([kernel, degree, gamma, …])\tUnsupervised Outlier Detection.  \n",
    "svm.SVC([C, kernel, degree, gamma, coef0, …])\tC-Support Vector Classification.  \n",
    "svm.SVR([kernel, degree, gamma, coef0, tol, …])\tEpsilon-Support Vector Regression.  \n",
    "svm.l1_min_c(X, y[, loss, fit_intercept, …])\tReturn the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty.\n",
    "\n",
    "\n",
    "svm.libsvm.cross_validation\tBinding of the cross-validation routine (low-level routine)  \n",
    "svm.libsvm.decision_function\tPredict margin (libsvm name for this is predict_values)  \n",
    "svm.libsvm.fit\tTrain the model using libsvm (low-level method)  \n",
    "svm.libsvm.predict\tPredict target values of X given a model (low-level method)  \n",
    "svm.libsvm.predict_proba\tPredict probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支持向量机\n",
    "\n",
    "[官网：Support Vector Machines](http://scikit-learn.org/stable/modules/svm.html)\n",
    "\n",
    "支持向量机 (SVMs) 可用于以下监督学习算法`分类`,`回归`和`异常检测`\n",
    "\n",
    "支持向量机的优势在于:\n",
    "\n",
    "- 在高维空间中非常高效.\n",
    "- 即使在数据维度比样本数量大的情况下仍然有效.\n",
    "- 在决策函数中使用训练点集的子集（称为支持向量）,因此它也是高效利用内存的.\n",
    "- 通用性: 不同的核函数与特定的决策函数一一对应.常见的 kernel 已经提供,也可以指定定制的内核.\n",
    "\n",
    "支持向量机的缺点包括:\n",
    "\n",
    "- 如果特征数量比样本数量大得多,在选择核函数 核函数 时要避免过拟合,而且正则化项是非常重要的.\n",
    "- 支持向量机不直接提供概率估计,这些都是使用昂贵的五次交叉验算计算的. (详情见 Scores and probabilities, 在下文中).\n",
    "\n",
    "在 scikit-learn 中,支持向量机同时支持dense(numpy.ndarray ,可以通过 numpy.asarray 进行转换) 和 sparse (任何 scipy.sparse) 样例向量作为输入.然而,要使用支持向量机来对 sparse 数据作预测,它必须已经拟合这样的数据.使用 C 代码的 numpy.ndarray (dense) 或者带有 dtype=float64 的 scipy.sparse.csr_matrix (sparse) 来优化性能."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC, NuSVC 和 LinearSVC 能在数据集中实现多元分类.\n",
    "\n",
    "SVC 和 NuSVC 是相似的方法, 但是接受稍许不同的参数设置并且有不同的数学方程(在这部分看 数学公式). 另一方面, LinearSVC 是另一个实现线性核函数的支持向量分类. 记住 LinearSVC 不接受关键词 kernel, 因为它被假设为线性的. 它也缺少一些 SVC 和 NuSVC 的成员(members) 比如 support_ .\n",
    "\n",
    "和其他分类器一样, SVC, NuSVC 和 LinearSVC 将两个数组作为输入: [n_samples, n_features] 大小的数组 X 作为训练样本, [n_samples] 大小的数组 y 作为类别标签(字符串或者整数):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "x = [[0,0],[1,1]]\n",
    "y = [0,1]\n",
    "clf = svm.SVC()\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获得支持向量\n",
    "clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获得支持向量的索引\n",
    "clf.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为每一个类别获得支持向量的数量\n",
    "clf.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多分类\n",
    "\n",
    "SVC 和 NuSVC 为多元分类实现了 “one-against-one” 的方法 (Knerr et al., 1990) 如果 n_class 是类别的数量, 那么 n_class * (n_class - 1) / 2 分类器被重构, 而且每一个从两个类别中训练数据. 为了给其他分类器提供一致的交互, decision_function_shape 选项允许聚合 “one-against-one” 分类器的结果成 (n_samples, n_classes) 的大小到决策函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1],[2],[3],[4]]\n",
    "y = [0,1,2,3]\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63212056,  0.98168436,  0.99987659,  0.3495638 ,  0.36775603,\n",
       "         0.01819223]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = clf.decision_function([[1]])\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function_shape = 'ovr'\n",
    "dec = clf.decision_functiontion([[1]])\n",
    "dec.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = lin_clf.decision_function([[1]])\n",
    "dec.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC 也实现了可选择的多类别策略, 通过使用选项 multi_class='crammer_singer'实现。  \n",
    "\n",
    "对于 “one-vs-rest” LinearSVC, 属性 coef_ 和 intercept_ 分别具有 [n_class, n_features] 和 [n_class] 尺寸. 系数的每一行符合 n_class 的许多 one-vs-rest 分类器之一, 并且就以这一类的顺序与拦截器(intercepts)相似.\n",
    "\n",
    "至于 one-vs-one SVC, 属性特征的布局(layout)有少多些复杂. 考虑到有一种线性核函数, coef_ 和 intercept_ 的布局(layout)与上文描述成 LinearSVC 相似, 除了 coef_ 的形状 [n_class * (n_class - 1) / 2, n_features], 与许多二元的分类器相似. 0到n的类别顺序是 “0 vs 1”, “0 vs 2” , … “0 vs n”, “1 vs 2”, “1 vs 3”, “1 vs n”, … “n-1 vs n”.\n",
    "\n",
    "dual_coef_ 的 shape 是 [n_class-1, n_SV], 这个结构有些难以理解. 对应于支持向量的列与 n_class * (n_class - 1) / 2 “one-vs-one” 分类器相关. 每一个支持向量用于 n_class - 1 分类器中.对于这些分类器,每一行的 n_class - 1 条目对应于对偶系数(dual coefficients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得分和概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当构造器(constructor)选项 probability 设置为 True 的时候, 类成员可能性评估开启.(来自 predict_proba 和 predict_log_proba 方法) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1],[-1, 1],[-2, 1]])\n",
    "y = np.array([1, 1, 2, 2, 3, 3])\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(X, y) \n",
    "\n",
    "print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00052254])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = clf.decision_function([[-1,-1]])\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00052254])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function_shape = 'ovo'\n",
    "dec = clf.decision_function([[-1,-1]])\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94150567,  0.04532333,  0.013171  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([[-1,-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非均衡问题\n",
    "\n",
    "这个问题期望给予某一类或某个别样例能使用的关键词 class_weight 和 sample_weight 提高权重(importance).\n",
    "\n",
    "SVC (而不是 NuSVC) 在 fit 方法中生成了一个关键词 class_weight. 它是形如 {class_label : value} 的字典, value 是浮点数大于 0 的值, 把类 class_label 的参数 C 设置为 C * value.\n",
    "\n",
    "SVC, NuSVC, SVR, NuSVR 和 OneClassSVM 在 fit 方法中通过关键词 sample_weight 为单一样例实现权重weights.与 class_weight 相似, 这些把第i个样例的参数 C 换成 C * sample_weight[i]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持向量分类的方法可以被扩展用作解决回归问题. 这个方法被称作支持向量回归.\n",
    "\n",
    "支持向量分类生成的模型(如前描述)只依赖于训练集的子集,因为构建模型的 cost function 不在乎边缘之外的训练点. 类似的,支持向量回归生成的模型只依赖于训练集的子集, 因为构建模型的 cost function 忽略任何接近于模型预测的训练数据.\n",
    "\n",
    "支持向量分类有三种不同的实现形式: SVR, NuSVR 和 LinearSVR. 在只考虑线性核的情况下, LinearSVR 比 SVR 提供一个更快的实现形式, 然而比起 SVR 和 LinearSVR, NuSVR 实现一个稍微不同的构思(formulation).\n",
    "\n",
    "与分类的类别一样, fit方法会调用参数向量 X, y, 只在 y 是浮点数而不是整数型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "clf = svm.SVR()\n",
    "clf.fit(X, y) \n",
    "\n",
    "\n",
    "clf.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 密度估计, 异常（novelty）检测\n",
    "\n",
    "单类别的 SVM 用于异常检测, 即给予一个样例集, 它会检测这个样例集的 soft boundary 以便给新的数据点分类, 看它是否属于这个样例集. 生成的类称作 OneClassSVM.\n",
    "\n",
    "这种情况下, 因为它属于非监督学习的一类, 没有类标签, fit 方法只会考虑输入数组X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 复杂度\n",
    "\n",
    "支持向量机是个强大的工具，不过它的计算和存储空间要求也会随着要训练向量的数目增加而快速增加。 SVM的核心是一个二次规划问题(Quadratic Programming, QP)，是将支持向量和训练数据的其余部分分离开来。 在实践中(数据集相关)，取决于实际使用libsvm缓存的效率，在O(n_{features} \\times n_{samples}^2) 和 O(n_{features} \\times n_{samples}^3)之间基于 libsvm 的缩放操作才会调用这个 QP 解析器。 如果数据是非常稀疏，那 n_{features} 就用样本向量中非零特征的平均数量去替换。\n",
    "\n",
    "另外请注意，在线性情况下，由 liblinear 操作的 LinearSVC 算法要比由它的 libsvm 对应的 SVC 更为高效，并且它几乎可以线性缩放到数百万样本或者特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用诀窍\n",
    "\n",
    "1. 避免数据复制: 对于 SVC， SVR， NuSVC 和 NuSVR， 如果数据是通过某些方法而不是用 C 有序的连续双精度，那它先会调用底层的 C 命令再复制。 您可以通过检查它的 flags 属性，来确定给定的 numpy 数组是不是 C 连续的。\n",
    "> 对于 LinearSVC (和 LogisticRegression) 的任何输入，都会以 numpy 数组形式，被复制和转换为 用 liblinear 内部稀疏数据去表达（双精度浮点型 float 和非零部分的 int32 索引）。 如果您想要一个适合大规模的线性分类器，又不打算复制一个密集的 C-contiguous 双精度 numpy 数组作为输入， 那我们建议您去使用 SGDClassifier 类作为替代。目标函数可以配置为和 LinearSVC 模型差不多相同的。\n",
    "2. 内核的缓存大小: 在大规模问题上，对于 SVC, SVR, nuSVC 和 NuSVR, 内核缓存的大小会特别影响到运行时间。如果您有足够可用的 RAM，不妨把它的 缓存大小 设得比默认的 200(MB) 要高，例如为 500(MB) 或者 1000(MB)。\n",
    "\n",
    "3. 惩罚系数C的设置:在合理的情况下， C 的默认选择为 1 。如果您有很多混杂的观察数据， 您应该要去调小它。 C 越小，就能更好地去正规化估计。\n",
    "\n",
    "4. 归一化和标准化数据。\n",
    "\n",
    "5. 在 NuSVC/OneClassSVM/NuSVR 内的参数 nu ， 近似是训练误差和支持向量的比值。\n",
    "\n",
    "6. 样本不均衡。在 SVC, ，如果分类器的数据不均衡（就是说，很多正例很少负例），设置 class_weight='balanced' 与/或尝试不同的惩罚系数 C 。\n",
    "\n",
    "7. 在拟合模型时，底层 LinearSVC 操作使用了随机数生成器去选择特征。 所以不要感到意外，对于相同的数据输入，也会略有不同的输出结果。如果这个发生了， 尝试用更小的 tol 参数。\n",
    "\n",
    "8. 特征筛选。使用由 LinearSVC(loss='l2', penalty='l1', dual=False) 提供的 L1 惩罚去产生稀疏解，也就是说，特征权重的子集不同于零，这样做有助于决策函数。 随着增加 C 会产生一个更复杂的模型（要做更多的特征选择）。可以使用 l1_min_c 去计算 C 的数值，去产生一个”null” 模型（所有的权重等于零）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核函数\n",
    "\n",
    "![](http://img.my.csdn.net/uploads/201302/25/1361786433_5005.jpg)\n",
    "\n",
    "1. 对于线性核函数，没有专门需要设置的参数\n",
    "2. 对于多项式核函数，有三个参数。-d用来设置多项式核函数的最高此项次数，也就是公式中的d，默认值是3。-g用来设置核函数中的gamma参数设置，也就是公式中的第一个r(gamma)，默认值是1/k（k是类别数）。-r用来设置核函数中的coef0，也就是公式中的第二个r，默认值是0。\n",
    "3. 对于RBF核函数，有一个参数。-g用来设置核函数中的gamma参数设置，也就是公式中的第一个r(gamma)，默认值是1/k（k是类别数）。\n",
    "4. 对于sigmoid核函数，有两个参数。-g用来设置核函数中的gamma参数设置，也就是公式中的第一个r(gamma)，默认值是1/k（k是类别数）。-r用来设置核函数中的coef0，也就是公式中的第二个r，默认值是0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rbf'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.kernel\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义核\n",
    "\n",
    "您可以自定义自己的核，通过使用python函数作为内核或者通过预计算 Gram 矩阵。\n",
    "\n",
    "自定义内核的分类器和别的分类器一样，除了下面这几点:\n",
    "\n",
    "空间 support_vectors_ 现在不是空的, 只有支持向量的索引被存储在 support_\n",
    "请把 fit() 模型中的第一个参数的引用（不是副本）存储为将来的引用。 如果在 fit() 和 predict() 之间有数组发生改变，您将会碰到意料外的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  使用 python 函数作为内核\n",
    "\n",
    "在构造时，您同样可以通过一个函数传递到关键词 kernel ，来使用您自己定义的内核。\n",
    "\n",
    "您的内核必须要以两个矩阵作为参数，大小分别是 (n_samples_1, n_features), (n_samples_2, n_features) 和返回一个内核矩阵，shape 是 (n_samples_1, n_samples_2).\n",
    "\n",
    "以下代码定义一个线性核，和构造一个使用该内核的分类器例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "def my_kernel(X, Y):\n",
    "    return np.dot(X, Y.T)\n",
    "\n",
    "clf = svm.SVC(kernel=my_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 Gram 矩阵\n",
    "\n",
    "在适应算法中，设置 kernel='precomputed' 和把 X 替换为 Gram 矩阵。 此时，必须要提供在 所有 训练矢量和测试矢量中的内核值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "X = np.array([[0, 0], [1, 1]])\n",
    "y = [0, 1]\n",
    "clf = svm.SVC(kernel='precomputed')\n",
    "# 线性内核计算\n",
    "gram = np.dot(X, X.T)\n",
    "clf.fit(gram, y) \n",
    "\n",
    "# 预测训练样本\n",
    "clf.predict(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF \n",
    "\n",
    "当用 径向基 (RBF) 内核去训练 SVM，有两个参数必须要去考虑： C 惩罚系数和 gamma 。参数 C ， 通用在所有 SVM 内核，与决策表面的简单性相抗衡，可以对训练样本的误分类进行有价转换。 较小的 C 会使决策表面更平滑，同时较高的 C 旨在正确地分类所有训练样本。 Gamma 定义了单一 训练样本能起到多大的影响。较大的 gamma 会更让其他样本受到影响。\n",
    "\n",
    "选择合适的 C 和 gamma ，对SVM的性能起到很关键的作用。建议一点是 使用  sklearn.model_selection.GridSearchCV 与 C 和 gamma 相隔 成倍差距从而选择到好的数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
